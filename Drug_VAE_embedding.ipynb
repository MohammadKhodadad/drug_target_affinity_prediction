{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6khgmzi-ra0d",
        "outputId": "f08162fe-7e6f-4b3d-9e59-dcabb4492a09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyTDC in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.10/dist-packages (from PyTDC) (2022.9.5)\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.10/dist-packages (from PyTDC) (0.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from PyTDC) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from PyTDC) (1.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from PyTDC) (4.66.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from PyTDC) (1.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from PyTDC) (0.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from PyTDC) (2.31.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from PyTDC) (0.19.4)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.10/dist-packages (from PyTDC) (0.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->PyTDC) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->PyTDC) (2023.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->PyTDC) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->PyTDC) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->PyTDC) (23.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->PyTDC) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->PyTDC) (2023.3.post1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi->PyTDC) (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->PyTDC) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->PyTDC) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->PyTDC) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->PyTDC) (2023.7.22)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->PyTDC) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->PyTDC) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->PyTDC) (3.2.0)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn->PyTDC) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->PyTDC) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->PyTDC) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->PyTDC) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->PyTDC) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->PyTDC) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->PyTDC) (1.16.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyTDC\n",
        "!pip install datasets\n",
        "\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from tdc.multi_pred import DTI\n",
        "from tdc.generation import MolGen\n",
        "import plotly.figure_factory as ff\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
      ],
      "metadata": {
        "id": "leGyYHrNrfAg"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = MolGen(name = 'MOSES')\n",
        "data=data.get_data()[:100000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpN9GJKcrgbC",
        "outputId": "72ea58e8-0198-4fd9-92cf-dc5c37e0211b"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Found local copy...\n",
            "Loading...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.sample(frac=1)\n",
        "data=data.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "7GTPJCrPuxIk"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some Basic Analysis"
      ],
      "metadata": {
        "id": "sAuRdYeXtf8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['l_smiles']=data.smiles.apply(len)"
      ],
      "metadata": {
        "id": "ZPPNyb-Zsu2H"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['l_smiles'].describe(percentiles=[i/10 for i in range(1,10)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9xHxyfLriKM",
        "outputId": "63629693-68c2-43fa-aa35-158389f63706"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    100000.000000\n",
              "mean         35.150310\n",
              "std           4.566592\n",
              "min          15.000000\n",
              "10%          29.000000\n",
              "20%          31.000000\n",
              "30%          33.000000\n",
              "40%          34.000000\n",
              "50%          35.000000\n",
              "60%          36.000000\n",
              "70%          38.000000\n",
              "80%          39.000000\n",
              "90%          41.000000\n",
              "max          54.000000\n",
              "Name: l_smiles, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A solid preset length for drug would be 50"
      ],
      "metadata": {
        "id": "2X1w4NI5tmtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(input_string):\n",
        "  return [ord(char) for char in input_string]\n",
        "def encode(input_string,max_length=128,padding=True):\n",
        "  tokens=tokenize(input_string)\n",
        "  if len(tokens)>max_length:\n",
        "    tokens=tokens[:max_length]\n",
        "  if (len(tokens)<max_length) & padding:\n",
        "    tokens.extend([0 for _ in range(max_length-len(tokens))])\n",
        "  return tokens\n",
        "def decode(input_tokens):\n",
        "  return ''.join(list(map(lambda x:chr(x), input_tokens)))"
      ],
      "metadata": {
        "id": "Xur6R70Arnye"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_tokenizer=encode('z',padding=False)[0]+1"
      ],
      "metadata": {
        "id": "1X_w-I0RuPfk"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Drug_Dataset(Dataset):\n",
        "    def __init__(self, df,drug_max_length):\n",
        "        self.df = df\n",
        "        self.dml=drug_max_length\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row=self.df.iloc[idx]\n",
        "        input_drug=torch.tensor(encode(row['smiles'],max_length=self.dml))\n",
        "        return {'input_drug':input_drug}"
      ],
      "metadata": {
        "id": "5VaFsFIouSxK"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dml=50"
      ],
      "metadata": {
        "id": "RvNEPWDXujUt"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l=int(data.shape[0]*0.8)\n",
        "train_p=Drug_Dataset(data[:l],drug_max_length=dml)\n",
        "test_p=Drug_Dataset(data[l:],drug_max_length=dml)"
      ],
      "metadata": {
        "id": "a16H4eWbunSr"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader=DataLoader(train_p,batch_size=32,shuffle=True)\n",
        "test_loader=DataLoader(test_p,batch_size=32)"
      ],
      "metadata": {
        "id": "3YIkiOK_uu0c"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's create the model"
      ],
      "metadata": {
        "id": "VyC9BHbTu9A7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This is Attention, as Torch's attention does not work with mask."
      ],
      "metadata": {
        "id": "0V_0xlhbvBjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim=8,embed_dim=16):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.latent_dim=latent_dim\n",
        "        self.embeddings = nn.Embedding(l_tokenizer, embed_dim)\n",
        "        self.conv1=nn.Conv1d(embed_dim,embed_dim//2,3)\n",
        "        self.pool1=nn.MaxPool1d(2)\n",
        "        self.conv2=nn.Conv1d(embed_dim//2,embed_dim//4,3)\n",
        "        self.pool2=nn.MaxPool1d(2)\n",
        "        self.conv3=nn.Conv1d(embed_dim//4,embed_dim//8,2)\n",
        "        self.pool3=nn.MaxPool1d(2)\n",
        "        self.linear3=nn.Linear((embed_dim//8)*5, latent_dim)\n",
        "\n",
        "        self.N = torch.distributions.Normal(0, 1)\n",
        "        # self.N.loc = self.N.loc # hack to get sampling on the GPU\n",
        "        self.N.scale = self.N.scale\n",
        "        self.kl = 0\n",
        "\n",
        "    def forward(self, x):\n",
        "        x=self.embeddings(x)\n",
        "        bn=x.size(0)\n",
        "        x=torch.transpose(x,1,2)\n",
        "        x = self.pool1(F.relu(self.conv1(x)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        x = self.pool3(F.relu(self.conv3(x)))\n",
        "        # x=torch.transpose(x,1,2)\n",
        "        x=x.view(bn,-1)\n",
        "        mu =  self.linear3(x)\n",
        "        sigma = torch.exp(self.linear3(x))\n",
        "        z = mu + sigma*(self.N.sample(mu.shape)).to(device)\n",
        "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum()/x.size(0)/dml/100\n",
        "        return z\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim=8,dim1=16):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.linear=nn.Linear(latent_dim,24)\n",
        "        self.conv1 = nn.ConvTranspose1d(1, dim1,3,stride=2)\n",
        "        self.conv2 = nn.ConvTranspose1d(dim1, 2*dim1,2)\n",
        "        self.linear2 = nn.Linear(2*dim1,l_tokenizer)\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = F.relu(self.linear(z))\n",
        "        z = z.view(-1,1,24)\n",
        "        z = F.relu(self.conv1(z))\n",
        "        z = F.relu(self.conv2(z))\n",
        "        z = torch.transpose(z,1,2)\n",
        "        z = self.linear2(z)\n",
        "        return z\n",
        "\n",
        "class VariationalAutoencoder(nn.Module):\n",
        "    def __init__(self, latent_dims=32):\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        self.encoder = Encoder(latent_dims,64).to(device)\n",
        "        self.decoder = Decoder(latent_dims,32).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        return self.decoder(z)"
      ],
      "metadata": {
        "id": "y4CwoD0PvNfd"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "autoencoder=VariationalAutoencoder()\n",
        "opt = torch.optim.Adam(autoencoder.parameters(),lr=0.0005)\n",
        "loss_fn=torch.nn.CrossEntropyLoss()\n",
        "def acc_fn(y,y_hat):\n",
        "  return torch.mean((y==torch.argmax(y_hat,dim=1)).float())\n",
        "for epoch in range(100):\n",
        "    train_loss1=0\n",
        "    train_loss2=0\n",
        "    train_acc=0\n",
        "    autoencoder.train()\n",
        "    for batch in tqdm.tqdm(train_loader):\n",
        "        x = batch['input_drug'].to(device) # GPU\n",
        "        opt.zero_grad()\n",
        "        x_hat = autoencoder(x)\n",
        "        # x2=torch.transpose(x,1,2)\n",
        "        x2_hat=torch.transpose(x_hat,1,2)\n",
        "        loss1=loss_fn(x2_hat,x)\n",
        "        loss2=autoencoder.encoder.kl\n",
        "        acc=acc_fn(x,x2_hat)\n",
        "        loss = loss1 + loss2\n",
        "        train_acc+=acc.detach().cpu().numpy()\n",
        "        train_loss1+=loss1.detach().cpu().numpy()\n",
        "        train_loss2+=loss2.detach().cpu().numpy()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    test_loss1=0\n",
        "    test_loss2=0\n",
        "    test_acc=0\n",
        "    autoencoder.eval()\n",
        "    with torch.no_grad():\n",
        "      for batch in tqdm.tqdm(test_loader):\n",
        "          x = batch['input_drug'].to(device) # GPU\n",
        "          x_hat = autoencoder(x)\n",
        "          # x2=torch.transpose(x,1,2)\n",
        "          x2_hat=torch.transpose(x_hat,1,2)\n",
        "          loss1=loss_fn(x2_hat,x)\n",
        "          loss2=autoencoder.encoder.kl\n",
        "          acc=acc_fn(x,x2_hat)\n",
        "          loss = loss1 + loss2\n",
        "          test_acc+=acc.detach().cpu().numpy()\n",
        "          test_loss1+=loss1.detach().cpu().numpy()\n",
        "          test_loss2+=loss2.detach().cpu().numpy()\n",
        "\n",
        "    print(f\"TRAIN: EPOCH {epoch}: SSE: {train_loss1/len(train_loader)}, KL_LOSS: {train_loss2/len(train_loader)}, ACC: {train_acc/len(train_loader)}   \\nTEST: EPOCH {epoch}: SSE: {test_loss1/len(test_loader)}, KL_LOSS: {test_loss2/len(test_loader)}, ACC: {test_acc/len(test_loader)}\")"
      ],
      "metadata": {
        "id": "UtIiLw_1UK73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zxbwLHJ00PVA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}